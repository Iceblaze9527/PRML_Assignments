# 第三次作业_2
> 新雅62/CDIE6 
> 2016013327 项雨桐

## 3.3 计算机小实验:用 Softmax 回归进行人脸识别
在课上我们已经学习了如何使用 Logistic Regression 进行二分类。请大家阅读 Softmax Regression 并回答以下问题。
  
### 3.1. Softmax Regression 是线性还是非线性分类器? 请说明你的理由

> 是线性分类器。虽然引入了非线性的softmax函数作为分类依据，但决策面仍然是线性函数
> $$
\operatorname{softmax}\left(\mathbf{x}_{i}\right)=\frac{e^{\mathbf{w}^{T}\mathbf{x}_{i}}}{\sum_{j=1}^{N} e^{\mathbf{w}^{T}\mathbf{x}_{j}}} \quad(i=1, \cdots, N)
$$

### 3.2. 在附件中我们给出了 10 个人的人脸图像。请用 Softmax Regression 设计分类器，实现以下要求:
- 请随机取出 2 个人的图像，75%作为训练集，25%作为测试集，给出 Softmax 的测试集正确率；同时，计算出 TPR，FPR，TNR，FNR，sensitivity，specificity，FDR；绘制 ROC 曲线，计算 AUC。
- 请随机取出 5 个人的图像，75%作为训练集，25%作为测试集，给出 Softmax 的测试集正确率。
- 请使用所有人的图像，75%作为训练集，25%作为测试集，给出 Softmax 的测试集正确率。
    
以上的测试中你的正确率是如何变化的，总结变化并给出合理解释。
> 输出参数如下
> ```
> 测试准确率:
> 2分类: 0.9267
> 5分类: 0.72
> 10分类: 0.6613
> 2分类性能参数:
> TPR: 0.9189
> FPR: 0.0658
> TNR: 0.9342
> FNR: 0.0811
> sensitivity: 0.9189
> specificity: 0.9342
> FDR: 0.0685
> AUC: 0.9881
> ```
> <img src="https://i.loli.net/2020/03/15/o5lzjqZMBsJDx3u.png"></img>
随着分类总数的增多，softmax分类器的准确率逐步下降。因为softmax分类器是把每一个分类结果映射为一个概率，之后再取概率最大的作为分类结果；对于多分类问题而言，所有种类的概率之和为1，除非各类别差异十分显著，随着种类数增多，各个概率允许的预测误差会更小，容错率降低，因此导致准确率降低。

## 4.3 计算机小实验:用多层感知器进行人脸识别
在第三章作业 3 中，我们 Softmax Regression 设计了人脸分类器，在本章中，请使用多层感知器进行同样的实验。讨论实验中多层感知器设计和训练中的因素对结果的影响，将本次实验结果与上次实验结果进行对比分析。

### 4.3.1 多层感知器设计和训练中的因素对结果的影响
实验参数设置如下表：

参数 | 默认值 | 实验值
-- | -- | --
hidden_layer_sizes | (256,) | (512,), (1024,), (256,256)
activation | relu | tanh
solver | adam | sgd
alpha | 0.0001 | 0.001
batch_size | 200 | 100
learning_rate_init | 0.001 | 0.0001
learning_rate | constant | adaptive
max_iter | 1000 | 500

#### 1. ( 512, ), default
```
测试准确率:
2分类: 0.8467
5分类: 0.7387
10分类: 0.7093
2分类性能参数:
TPR: 0.725
FPR: 0.0143
TNR: 0.9857
FNR: 0.275
sensitivity: 0.725
specificity: 0.9857
FDR: 0.0169
AUC: 0.9436
```
![ROC_01.png](https://i.loli.net/2020/03/15/yvKwzDcp5Ibf9iW.png)

#### 2. ( 256, ), default
```
测试准确率:
2分类: 0.8867
5分类: 0.7467
10分类: 0.6907
2分类性能参数:
TPR: 0.8875
FPR: 0.1143
TNR: 0.8857
FNR: 0.1125
sensitivity: 0.8875
specificity: 0.8857
FDR: 0.1013
AUC: 0.9473
```
![ROC_02.png](https://i.loli.net/2020/03/15/u75bJ1yFgaKjzZW.png)

#### 3. ( 1024, ), default
```
测试准确率:
2分类: 0.8933
5分类: 0.7467
10分类: 0.6973
2分类性能参数:
TPR: 0.9125
FPR: 0.1286
TNR: 0.8714
FNR: 0.0875
sensitivity: 0.9125
specificity: 0.8714
FDR: 0.1098
AUC: 0.9457
```
![ROC_03.png](https://i.loli.net/2020/03/15/CtFPV4mvqLieGEw.png)

#### 4. ( 256, 256 ), default
```
测试准确率:
2分类: 0.8867
5分类: 0.7467
10分类: 0.7093
2分类性能参数:
TPR: 0.85
FPR: 0.0714
TNR: 0.9286
FNR: 0.15
sensitivity: 0.85
specificity: 0.9286
FDR: 0.0685
AUC: 0.9482
```
![ROC_04.png](https://i.loli.net/2020/03/15/5hBXGb9Y1mPQ2O8.png)

#### 5. ( 256, ), activation="tanh"
```
测试准确率:
2分类: 0.8733
5分类: 0.7627
10分类: 0.7307
2分类性能参数:
TPR: 0.8125
FPR: 0.0571
TNR: 0.9429
FNR: 0.1875
sensitivity: 0.8125
specificity: 0.9429
FDR: 0.058
AUC: 0.9488
```
![ROC_05.png](https://i.loli.net/2020/03/15/GaHl5bLA7nZrkvX.png)

#### 6. ( 256, ), solver=sgd", max_iter=2000
```
测试准确率:
2分类: 0.88
5分类: 0.744
10分类: 0.7
2分类性能参数:
TPR: 0.85
FPR: 0.0857
TNR: 0.9143
FNR: 0.15
sensitivity: 0.85
specificity: 0.9143
FDR: 0.0811
AUC: 0.9491
```
![ROC_06.png](https://i.loli.net/2020/03/15/uTO1zl5WDBAgb9n.png)

#### 7. ( 256, ), alpha=0.001
```
测试准确率:
2分类: 0.88
5分类: 0.7227
10分类: 0.668
2分类性能参数:
TPR: 0.8375
FPR: 0.0714
TNR: 0.9286
FNR: 0.1625
sensitivity: 0.8375
specificity: 0.9286
FDR: 0.0694
AUC: 0.9479
```
![ROC_07.png](https://i.loli.net/2020/03/15/3cbZelLhVqwAkRv.png)

#### 8. ( 256, ), batch_size=100
```
测试准确率:
2分类: 0.9
5分类: 0.7227
10分类: 0.668
2分类性能参数:
TPR: 0.875
FPR: 0.0714
TNR: 0.9286
FNR: 0.125
sensitivity: 0.875
specificity: 0.9286
FDR: 0.0667
AUC: 0.9505
```
![ROC_08.png](https://i.loli.net/2020/03/15/gykVxPnAor13j68.png)

#### 9. ( 256, ), learning_rate_init=0.0001
```
测试准确率:
2分类: 0.8867
5分类: 0.7493
10分类: 0.7
2分类性能参数:
TPR: 0.8625
FPR: 0.0857
TNR: 0.9143
FNR: 0.1375
sensitivity: 0.8625
specificity: 0.9143
FDR: 0.08
AUC: 0.9562
```
![ROC_09.png](https://i.loli.net/2020/03/15/cVJChij8dFQvmHS.png)

#### 10. ( 256, ), learning_rate="adaptive"
```
测试准确率:
2分类: 0.8667
5分类: 0.7227
10分类: 0.6747
2分类性能参数:
TPR: 0.8125
FPR: 0.0714
TNR: 0.9286
FNR: 0.1875
sensitivity: 0.8125
specificity: 0.9286
FDR: 0.0714
AUC: 0.9495
```
![ROC_10.png](https://i.loli.net/2020/03/15/mTiAofIlDNsB3ng.png)

#### 11. ( 256, ), max_iter=500
```
测试准确率:
2分类: 0.88
5分类: 0.7467
10分类: 0.6853
2分类性能参数:
TPR: 0.8375
FPR: 0.0714
TNR: 0.9286
FNR: 0.1625
sensitivity: 0.8375
specificity: 0.9286
FDR: 0.0694
AUC: 0.9495
```
![ROC_11.png](https://i.loli.net/2020/03/15/baJxkQB9dleyH3v.png)

#### 总结

影响多层感知器性能的超参数有感知器层数和每层节点数、激活函数、优化器、正则化程度、数据batch大小、学习率、训练世代数等等。这些超参数对多层感知器性能的影响比较复杂。本实验中，各超参数对感知器准确率的影响的变化趋势不十分显著，但如果有些参数不合适会导致模型收敛较慢（例如``sgd``算法）。

实验中针对2分类、5分类和10分类问题准确率最高的超参数组合为``batch_size=100 (0.9)``，``activation=tanh (0.7627)``和``activation=tanh (0.7307)``（其余保持默认值）。

### 4.3.2 对比分析

#### 两个模型的共性
* 随分类个数的增加准确率降低

#### 两个模型的不同
* softmax是线性分类器，MLP是非线性分类器
* softmax在分类个数较少的情况下有优势；MLP在多分类中更有优势
* softmax计算更简单，MLP模型复杂度更高、需要多次迭代才能收敛
* softmax超参数较少，MLP超参数较多
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTYwOTE0MzU5XX0=
-->