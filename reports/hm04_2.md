# 第四次作业_2
> 新雅62/CDIE6 
> 2016013327 项雨桐

## 5.4 计算机小实验:用 SVM 进行人脸识别
在第三章作业 3 和第四章作业 3 中，我们分别用 Softmax Regression 和多层感知器设计了人脸分类器，在本章中，请使用 SVM 进行同样的实验。讨论实验中核函数及其参数选择对结果的影响，将本次实验结果与之前的实验结果进行对比分析。

### 5.4.1 实验结果

实验参数设置如下表：

参数 | 默认值 | 实验值
-- | -- | --
kernel | 'rbf' | 'linear', 'poly', 'sigmoid'
C | 1.0 | 0.1
degree (poly only) | 3 | 2,5
gamma | 'scale=1/(n_features * X.var())' | 0.05

#### 1. default ( kernel='rbf' )
```
测试准确率:
2分类: 0.8933
5分类: 0.7387
10分类: 0.6613
2分类性能参数:
TPR: 0.85
FPR: 0.0571
TNR: 0.9429
FNR: 0.15
sensitivity: 0.85
specificity: 0.9429
FDR: 0.0556
AUC: 0.9562
```
![ROC_svm_01.png](https://i.loli.net/2020/03/18/KqS39QiZvhcHtLJ.png)

#### 2. C=0.1
```
测试准确率:
2分类: 0.7933
5分类: 0.5653
10分类: 0.4853
2分类性能参数:
TPR: 0.725
FPR: 0.1286
TNR: 0.8714
FNR: 0.275
sensitivity: 0.725
specificity: 0.8714
FDR: 0.1343
AUC: 0.8955
```
![ROC_svm_02.png](https://i.loli.net/2020/03/18/ZzRAPlD2mNvoKV5.png)

#### 3. kernel='linear'
```
测试准确率:
2分类: 0.8667
5分类: 0.7227
10分类: 0.6293
2分类性能参数:
TPR: 0.875
FPR: 0.1429
TNR: 0.8571
FNR: 0.125
sensitivity: 0.875
specificity: 0.8571
FDR: 0.125
AUC: 0.9277
```
![ROC_svm_03.png](https://i.loli.net/2020/03/18/Sgkwbx2hEzi1CPv.png)

#### 4. kernel='sigmoid'
```
测试准确率:
2分类: 0.3867
5分类: 0.2
10分类: 0.0653
2分类性能参数:
TPR: 0.0875
FPR: 0.2714
TNR: 0.7286
FNR: 0.9125
sensitivity: 0.0875
specificity: 0.7286
FDR: 0.7308
AUC: 0.3341
```
![ROC_svm_04.png](https://i.loli.net/2020/03/18/2HISdxfrDX1Vvz9.png)

#### 5. kernel=poly', degree=3
```
测试准确率:
2分类: 0.88
5分类: 0.7253
10分类: 0.6547
2分类性能参数:
TPR: 0.9
FPR: 0.1429
TNR: 0.8571
FNR: 0.1
sensitivity: 0.9
specificity: 0.8571
FDR: 0.122
AUC: 0.9329
```
![ROC_svm_05.png](https://i.loli.net/2020/03/18/E2OCW4fpUugl9D7.png)

#### 6. kernel=poly', degree=2
```
测试准确率:
2分类: 0.8933
5分类: 0.7413
10分类: 0.6773
2分类性能参数:
TPR: 0.875
FPR: 0.0857
TNR: 0.9143
FNR: 0.125
sensitivity: 0.875
specificity: 0.9143
FDR: 0.0789
AUC: 0.9434
```
![ROC_svm_06.png](https://i.loli.net/2020/03/18/A61CO25sD3TpLJt.png)

#### 7. kernel=poly', degree=5
```
测试准确率:
2分类: 0.82
5分类: 0.6613
10分类: 0.6
2分类性能参数:
TPR: 0.85
FPR: 0.2143
TNR: 0.7857
FNR: 0.15
sensitivity: 0.85
specificity: 0.7857
FDR: 0.1807
AUC: 0.9264
```
![ROC_svm_07.png](https://i.loli.net/2020/03/18/MDGfQKVCJXnwozs.png)

#### 8. gamma=0.05
```
测试准确率:
2分类: 0.7933
5分类: 0.6213
10分类: 0.5733
2分类性能参数:
TPR: 0.625
FPR: 0.0143
TNR: 0.9857
FNR: 0.375
sensitivity: 0.625
specificity: 0.9857
FDR: 0.0196
AUC: 0.9418
```
![ROC_svm_08.png](https://i.loli.net/2020/03/18/8t1sIMjPKmJNi2z.png)

### 5.4.2 核函数及其参数选择对结果的影响
#### 核函数
从上述实验1，3，4，5，6，7中可以看出：
- 如果参数选择合适，径向基核函数、线性核函数，多项式核函数的准确率相差不大，所以应用时可以选择计算量较小的一个
- 多项式核函数的最优幂次是2，之后因为模型复杂度逐渐增高，出现过拟合现象
- sigmoid核函数在一定参数下不满足Mercer条件，无法映射为高维空间的内积，因此出现准确率小于50%的现象
- 本次实验的最优的核函数为二次多项式

#### 参数选择
SVM主要有两个参数：$C$ 和 $\gamma$

- $C$：正则项系数，抑制过拟合。正则项系数越大，模型复杂度越低，倾向于欠拟合；反之复杂度越高，倾向于过拟合
- $\gamma$：对于RBF，$\gamma$ 是高斯分布的幅宽（与协方差矩阵有关）。幅宽越大，协方差越小，模型倾向过拟合；反之协方差越大，模型更平滑，倾向于欠拟合

从实验1，2，8中可以看出，减小 $C$ 、增大 $\gamma$ 使得模型发生了过拟合现象，准确率降低

### 5.4.3 对比分析
#### 模型的共性
* 随分类个数的增加准确率降低
* 参数合适的情况下，三个模型的准确率差别不大

#### 模型的不同
* softmax是线性分类器；MLP是非线性分类器；SVM可以实现线性分类也可实现非线性分类（转换为高维的线性分类问题）
* softmax、SVM在分类个数较少的情况下有优势；MLP在多分类中更有优势
* softmax计算更简单；MLP模型复杂度更高、需要多次迭代才能收敛；SVM的复杂性取决于核函数
* softmax、SVM超参数较少，MLP超参数较多
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTQ4MDQ0NjY3OV19
-->